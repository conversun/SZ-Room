version: '3.8'

services:
  sz-room-crawler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: sz-room-crawler
    restart: unless-stopped
    
    environment:
      - NODE_ENV=production
      - TZ=Asia/Shanghai
      
    env_file:
      - .env
      
    volumes:
      - ./logs:/app/logs
      - /etc/localtime:/etc/localtime:ro
      
    networks:
      - crawler-network
      
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        
    healthcheck:
      test: ["CMD", "node", "-e", "console.log('Health check')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
      
    # 如果需要外部访问，可以暴露端口
    # ports:
    #   - "3000:3000"

networks:
  crawler-network:
    driver: bridge

# 如果需要持久化数据，可以添加数据卷
# volumes:
#   crawler-data: 