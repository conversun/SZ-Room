version: '3.8'

services:
  redis:
    image: public.ecr.aws/docker/library/redis:7
    container_name: sz-room-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - crawler-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  sz-room-crawler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: sz-room-crawler
    restart: unless-stopped
    
    environment:
      - NODE_ENV=production
      - TZ=Asia/Shanghai
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      
    env_file:
      - .env
      
    volumes:
      - ./logs:/app/logs
      - /etc/localtime:/etc/localtime:ro
      
    networks:
      - crawler-network
      
    depends_on:
      - redis
      
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        
    healthcheck:
      test: ["CMD", "node", "-e", "console.log('Health check')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
      
    # 如果需要外部访问，可以暴露端口
    # ports:
    #   - "3000:3000"

networks:
  crawler-network:
    driver: bridge

# 如果需要持久化数据，可以添加数据卷
# volumes:
#   crawler-data: 

volumes:
  redis-data:
    driver: local